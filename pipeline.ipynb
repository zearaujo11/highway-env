{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL for Autonomous Vehicle Tasks: Safety and Traffic Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define agents here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:488: RuntimeWarning: Your system is avx2 capable but pygame was not built with support for it. The performance of some of your blits could be adversely affected. Consider enabling compile time detection with environment variables like PYGAME_DETECT_AVX2=1 if you are compiling without cross compilation.\n"
     ]
    }
   ],
   "source": [
    "import gymnasium\n",
    "import highway_env\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from stable_baselines3 import DQN\n",
    "import logging\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lane Changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_changing_env = gymnasium.make('highway-v0', render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roundabout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "roundabout_env = gymnasium.make('roundabout-v0', render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overtaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "overtaking_env = gymnasium.make('highway-v0', render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def create_directory(path):\n",
    "    \"\"\"\n",
    "    Create directory if it doesn't exist\n",
    "    \n",
    "    Args:\n",
    "        path (str): Directory path to create\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        logger.info(f\"Directory created: {path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating directory {path}: {e}\")\n",
    "\n",
    "def save_pipeline_data(agent_name, stage, environment_name, data):\n",
    "    \"\"\"\n",
    "    Save pipeline stage data\n",
    "    \n",
    "    Args:\n",
    "        agent_name (str): Name of the RL agent\n",
    "        stage (str): Current pipeline stage\n",
    "        environment_name (str): Name of the environment\n",
    "        data (dict): Data to be saved\n",
    "    \"\"\"\n",
    "    create_directory(f\"results/{agent_name}\")\n",
    "    \n",
    "    try:\n",
    "        filename = f\"results/{agent_name}/{environment_name}_data.json\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "        logger.info(f\"Data saved for {stage} in {environment_name}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(agent, environment, agent_name, stage, environment_name, num_episodes=3):\n",
    "    \"\"\"\n",
    "    Test the agent in a specific environment and record results\n",
    "    \n",
    "    Args:\n",
    "        agent (sb3.BaseAlgorithm): RL agent to test\n",
    "        environment (gym.Env): Environment to test in\n",
    "        agent_name (str): Name of the agent\n",
    "        stage (str): Current pipeline stage\n",
    "        environment_name (str): Name of the environment\n",
    "        num_episodes (int, optional): Number of test episodes. Defaults to 3.\n",
    "    \n",
    "    Returns:\n",
    "        List of test episode data\n",
    "    \"\"\"\n",
    "    test_results = []\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        try:\n",
    "            obs, info = environment.reset()\n",
    "            done = truncated = False\n",
    "            episode_data = {\n",
    "                'episode': episode,\n",
    "                'total_reward': 0,\n",
    "                'steps': [],\n",
    "                'final_info': None\n",
    "            }\n",
    "            \n",
    "            while not (done or truncated):\n",
    "                action, _states = agent.predict(obs, deterministic=True)\n",
    "                obs, reward, done, truncated, info = environment.step(action)\n",
    "                \n",
    "                episode_data['total_reward'] += reward\n",
    "                episode_data['steps'].append({\n",
    "                    'observation': obs.tolist() if hasattr(obs, 'tolist') else str(obs),\n",
    "                    'action': action.tolist() if hasattr(action, 'tolist') else str(action),\n",
    "                    'reward': reward\n",
    "                })\n",
    "                \n",
    "                # Optional rendering (comment out if not needed)\n",
    "                environment.render()\n",
    "            \n",
    "            episode_data['final_info'] = info\n",
    "            test_results.append(episode_data)\n",
    "            environment.close()\n",
    "            logger.info(f\"Test episode {episode + 1} completed in {environment_name}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Test episode {episode + 1} failed in {environment_name}: {e}\")\n",
    "    \n",
    "    # Save test results\n",
    "    save_pipeline_data(agent_name, stage, environment_name, {\n",
    "        'test_results': test_results,\n",
    "        'environment': environment_name,\n",
    "        'stage': stage\n",
    "    })\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "def train(agent, environment, agent_name, stage, environment_name, timesteps=100):\n",
    "    \"\"\"\n",
    "    Train the agent in a specific environment and save the model\n",
    "    \n",
    "    Args:\n",
    "        agent (sb3.BaseAlgorithm): RL agent to train\n",
    "        environment (gym.Env): Environment to train in\n",
    "        agent_name (str): Name of the agent\n",
    "        stage (str): Current pipeline stage\n",
    "        environment_name (str): Name of the environment\n",
    "        timesteps (int, optional): Number of training timesteps. Defaults to 100.\n",
    "    \n",
    "    Returns:\n",
    "        Trained agent\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set environment and learn\n",
    "        agent.set_env(environment)\n",
    "        training_results = agent.learn(total_timesteps=timesteps)\n",
    "        \n",
    "        # Create directories for model and results\n",
    "        create_directory(f\"models/{agent_name}/{stage}\")\n",
    "        \n",
    "        # Save model\n",
    "        agent.save(f\"models/{agent_name}/{stage}/{environment_name}_model\")\n",
    "        \n",
    "        # Prepare and save training information\n",
    "        training_info = {\n",
    "            'agent_name': agent_name,\n",
    "            'environment_name': environment_name,\n",
    "            'stage': stage,\n",
    "            'total_timesteps': timesteps,\n",
    "            'training_results': str(training_results)\n",
    "        }\n",
    "        save_pipeline_data(agent_name, stage, environment_name, training_info)\n",
    "        \n",
    "        logger.info(f\"Training completed for {agent_name} in {environment_name}\")\n",
    "        return agent\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Training failed for {agent_name} in {environment_name}: {e}\")\n",
    "        raise\n",
    "\n",
    "def rl_pipeline(initial_agent, agent_name, lane_changing_env, roundabout_env, overtaking_env):\n",
    "    \"\"\"\n",
    "    Sequential environment training pipeline\n",
    "    \n",
    "    Args:\n",
    "        initial_agent (sb3.BaseAlgorithm): Initial RL agent\n",
    "        agent_name (str): Name of the agent\n",
    "        lane_changing_env (gym.Env): Lane changing environment\n",
    "        roundabout_env (gym.Env): Roundabout environment\n",
    "        overtaking_env (gym.Env): Overtaking environment\n",
    "    \n",
    "    Returns:\n",
    "        Trained agent\n",
    "    \"\"\"\n",
    "    logger.info(\"Sequential Environment Pipeline Started\")\n",
    "    \n",
    "    # Stage 1: Lane Changing\n",
    "    logger.info(\"Stage 1: Lane Changing Environment\")\n",
    "    \n",
    "    # Train in Lane Changing\n",
    "    lane_changing_agent = train(\n",
    "        initial_agent, lane_changing_env, \n",
    "        agent_name, 'lane_changing', 'lane_changing'\n",
    "    )\n",
    "    \n",
    "    # Test in Lane Changing\n",
    "    test(\n",
    "        lane_changing_agent, lane_changing_env, \n",
    "        agent_name, 'pos_training_test', 'lane_changing'\n",
    "    )\n",
    "    \n",
    "    # Stage 2: Roundabout\n",
    "    logger.info(\"Stage 2: Roundabout Environment\")\n",
    "    \n",
    "    # First, test the lane changing agent in roundabout\n",
    "    test(\n",
    "        lane_changing_agent, roundabout_env, \n",
    "        agent_name, 'pre_training_test', 'roundabout'\n",
    "    )\n",
    "    \n",
    "    # Then train in Roundabout\n",
    "    roundabout_agent = train(\n",
    "        lane_changing_agent, roundabout_env, \n",
    "        agent_name, 'roundabout', 'roundabout'\n",
    "    )\n",
    "    \n",
    "    # Test in Roundabout\n",
    "    test(\n",
    "        roundabout_agent, roundabout_env, \n",
    "        agent_name, 'pos_train_test', 'roundabout'\n",
    "    )\n",
    "    \n",
    "    # Stage 3: Overtaking\n",
    "    logger.info(\"Stage 3: Overtaking Environment\")\n",
    "    \n",
    "    # First, test the roundabout agent in overtaking\n",
    "    test(\n",
    "        roundabout_agent, overtaking_env, \n",
    "        agent_name, 'pre_training_test', 'overtaking'\n",
    "    )\n",
    "    \n",
    "    # Then train in Overtaking\n",
    "    overtaking_agent = train(\n",
    "        roundabout_agent, overtaking_env, \n",
    "        agent_name, 'overtaking', 'overtaking'\n",
    "    )\n",
    "    \n",
    "    # Test in Overtaking\n",
    "    test(\n",
    "        overtaking_agent, overtaking_env, \n",
    "        agent_name, 'pos_training_test', 'overtaking'\n",
    "    )\n",
    "    \n",
    "    logger.info(\"Sequential Environment Pipeline Completed\")\n",
    "\n",
    "    # Save the final agent\n",
    "    create_directory(f\"models/{agent_name}/final\")\n",
    "    overtaking_agent.save(f\"models/{agent_name}/{agent_name}_final_model\")\n",
    "    \n",
    "    return overtaking_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Agent 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 10:10:05,998 - INFO - Sequential Environment Pipeline Started\n",
      "2024-11-21 10:10:05,998 - INFO - Stage 1: Lane Changing Environment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7        |\n",
      "|    ep_rew_mean      | 5.3      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 28       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 5.75     |\n",
      "|    ep_rew_mean      | 4.16     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 46       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 7.25     |\n",
      "|    ep_rew_mean      | 5.35     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 2        |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 87       |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 10:10:39,352 - INFO - Directory created: models/agent_DQN/stage1_lane_changing\n",
      "2024-11-21 10:10:39,358 - INFO - Directory created: results/agent_DQN\n",
      "2024-11-21 10:10:39,359 - INFO - Data saved for stage1_lane_changing in lane_changing\n",
      "2024-11-21 10:10:39,360 - INFO - Training completed for agent_DQN in lane_changing\n",
      "2024-11-21 10:10:50,952 - INFO - Test episode 1 completed in lane_changing\n",
      "2024-11-21 10:11:00,075 - INFO - Test episode 2 completed in lane_changing\n",
      "2024-11-21 10:11:10,181 - INFO - Test episode 3 completed in lane_changing\n",
      "2024-11-21 10:11:10,182 - INFO - Directory created: results/agent_DQN\n",
      "2024-11-21 10:11:10,188 - ERROR - Error saving data: Object of type ndarray is not JSON serializable\n",
      "2024-11-21 10:11:10,189 - INFO - Stage 2: Roundabout Environment\n",
      "2024-11-21 10:11:13,106 - INFO - Test episode 1 completed in roundabout\n",
      "2024-11-21 10:11:16,127 - INFO - Test episode 2 completed in roundabout\n",
      "2024-11-21 10:11:19,081 - INFO - Test episode 3 completed in roundabout\n",
      "2024-11-21 10:11:19,082 - INFO - Directory created: results/agent_DQN\n",
      "2024-11-21 10:11:19,085 - ERROR - Error saving data: Object of type ndarray is not JSON serializable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11       |\n",
      "|    ep_rew_mean      | 9.67     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 44       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.12     |\n",
      "|    ep_rew_mean      | 7.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 27       |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 73       |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 10:11:22,775 - INFO - Directory created: models/agent_DQN/stage2_roundabout\n",
      "2024-11-21 10:11:22,781 - INFO - Directory created: results/agent_DQN\n",
      "2024-11-21 10:11:22,781 - INFO - Data saved for stage2_roundabout in roundabout\n",
      "2024-11-21 10:11:22,782 - INFO - Training completed for agent_DQN in roundabout\n",
      "2024-11-21 10:11:25,724 - INFO - Test episode 1 completed in roundabout\n",
      "2024-11-21 10:11:28,668 - INFO - Test episode 2 completed in roundabout\n",
      "2024-11-21 10:11:30,089 - INFO - Test episode 3 completed in roundabout\n",
      "2024-11-21 10:11:30,092 - INFO - Directory created: results/agent_DQN\n",
      "2024-11-21 10:11:30,095 - ERROR - Error saving data: Object of type ndarray is not JSON serializable\n",
      "2024-11-21 10:11:30,097 - INFO - Stage 3: Overtaking Environment\n",
      "2024-11-21 10:11:45,428 - INFO - Test episode 1 completed in overtaking\n",
      "2024-11-21 10:11:47,918 - INFO - Test episode 2 completed in overtaking\n",
      "2024-11-21 10:11:49,715 - INFO - Test episode 3 completed in overtaking\n",
      "2024-11-21 10:11:49,716 - INFO - Directory created: results/agent_DQN\n",
      "2024-11-21 10:11:49,721 - ERROR - Error saving data: Object of type ndarray is not JSON serializable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20       |\n",
      "|    ep_rew_mean      | 15.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 80       |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 10:12:22,382 - INFO - Directory created: models/agent_DQN/stage3_overtaking\n",
      "2024-11-21 10:12:22,388 - INFO - Directory created: results/agent_DQN\n",
      "2024-11-21 10:12:22,388 - INFO - Data saved for stage3_overtaking in overtaking\n",
      "2024-11-21 10:12:22,389 - INFO - Training completed for agent_DQN in overtaking\n",
      "2024-11-21 10:12:29,303 - INFO - Test episode 1 completed in overtaking\n",
      "2024-11-21 10:12:31,069 - INFO - Test episode 2 completed in overtaking\n",
      "2024-11-21 10:12:38,564 - INFO - Test episode 3 completed in overtaking\n",
      "2024-11-21 10:12:38,565 - INFO - Directory created: results/agent_DQN\n",
      "2024-11-21 10:12:38,575 - ERROR - Error saving data: Object of type ndarray is not JSON serializable\n",
      "2024-11-21 10:12:38,576 - INFO - Sequential Environment Pipeline Completed\n"
     ]
    }
   ],
   "source": [
    "# Execute the pipeline to agent 1\n",
    "\n",
    "# a1_results = pipeline(...)\n",
    "\n",
    "# Display Results\n",
    "\n",
    "agent_DQN = DQN('MlpPolicy', lane_changing_env,\n",
    "        policy_kwargs=dict(net_arch=[256, 256]),\n",
    "        learning_rate=5e-4,\n",
    "        buffer_size=15000,\n",
    "        learning_starts=200,\n",
    "        batch_size=32,\n",
    "        gamma=0.8,\n",
    "        train_freq=1,\n",
    "        gradient_steps=1,\n",
    "        target_update_interval=50,\n",
    "        verbose=1)\n",
    "\n",
    "final_agent_DQN = rl_pipeline(agent_DQN, 'agent_DQN', lane_changing_env, roundabout_env, overtaking_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Agent N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
